{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.7.8","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Финальная самостоятельная работа :)\n\nНи пуха, ни пера!","metadata":{}},{"cell_type":"code","source":"# добрые гномы подсказывают как могут!!!\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n# - Фил, как там дальше?\ndf = pd.read_csv('data.csv')\n#######task 1.1#########\ndf.drop(df[df['ekz_final'] == 'неявка'].index, inplace = True) \n#######task 1.2#########\nres=[]\nfor li in df['ekz_final']:\n    if int(li) >= 4 : res.append(1)\n    else:   res.append(0)\ndf['pass'] = res\nprint(df)\n########task 1.3#######\nimport matplotlib.pyplot as plt\nplt.scatter(y=df['ekz_I'], x=df['ekz_final'])\nplt.show()\n########task 1.4#######\nlili = [\"k1\", \"k2_min\", \"k2_probs\", \"dc\", \"ekz_I\", \"lecture_test\", \"k3\", \"k4\", \"auditorka\", \"ekz_final\"]\nfor li in lili:\n    df.loc[df[li].isnull(), li] = df[li].mean()\ndf.loc[df[\"k1\"].isnull(), \"k1\"] = df[\"k1\"].mean()\ndf.loc[df[\"k2_min\"].isnull(), \"k2_min\"] = df[\"k2_min\"].mean()\ndf.loc[df[\"k2_probs\"].isnull(), \"k2_probs\"] = df[\"k2_probs\"].mean()\ndf.loc[df[\"dc\"].isnull(), \"dc\"] = df[\"dc\"].mean()\ndf.loc[df[\"ekz_I\"].isnull(), \"ekz_I\"] = df[\"ekz_I\"].mean()\ndf.loc[df[\"lecture_test\"].isnull(), \"lecture_test\"] = df[\"lecture_test\"].mean()\ndf.loc[df[\"k3\"].isnull(), \"k3\"] = df[\"k3\"].mean()\ndf.loc[df[\"k4\"].isnull(), \"k4\"] = df[\"k4\"].mean()\ndf.loc[df[\"auditorka\"].isnull(), \"auditorka\"] = df[\"auditorka\"].mean()\ndf.loc[df[\"ekz_final\"].isnull(), \"ekz_final\"] = df[\"ekz_final\"].mean()\n####### task 1.5####\n(test, learn) = np.split(df, [int(.2 * len(df))])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Задачулька 1\n\nПеред тобой результаты по теории вероятностей студентов одного из прошедших годов.\n\n> group — группа студента\n\n> ekz_final — финальный экзамен, переменная, которую мы будем предсказывать\n\n> остальные переменные — различные формы контроля до финального экзамена\n\n1. Удали из выборки данные студентов, не явившихся на финальный экзамен.\n\n2. Создай переменную pass равную единице для студентов, сдавших экзамен на 4 и выше, и нулю иначе.\n\n3. Построй диаграмму рассеяния оценки за финальный экзамен (ekz_final) и оценки за промежуточный экзамен (ekz_I).\n\n4. Заполни все пропуски в числовых переменных медианным значением, пропуск в группе можно считать особой группой и не заполнять.\n\n5. Раздели всю выборку на две части: обучающую 80% и тестовую 20%.\n\n*Подсказка от добрых гномов: ты ведь помнишь, что неплохо фиксировать зерно, чтобы всходы были реплицируемы?*","metadata":{}},{"cell_type":"markdown","source":"## Задачулька 2\n\nСейчас мы прогнозируем ekz_final.\n\n1. На обучающей выборке оцени простую регрессию для прогнозирования.\n\n2. На обучающей выборке оцени LASSO-регрессию с подбором штрафного коэффициента с помощью кросс-валидации.\n\n3. На обучающей выборке оцени гребневую (ridge) регрессию с подбором штрафного коэффициента с помощью кросс-валидации.\n\n4. На обучающей выборке построй случайный лес из 1000 деревьев. \n\n5. Сравни качество всех построенных моделей на тестовой выборке.\n\n\nЧисло групп (fold) в кросс-валидации бери равным пяти, в качестве целевого показателя — среднеквадратичную ошибку (MSE).\nГруппу студента в моделях (1)-(2)-(3) можно не учитывать. \n\n*Подсказка от добрых гномов: ты ведь помнишь, что для каких-то там алгоритмов данные надо масштабировать?*","metadata":{}},{"cell_type":"markdown","source":"## Задачулька 3\n\nСейчас мы прогнозируем pass.\n\n1. На обучающей выборке оцени логистическую регрессию без штрафа для прогнозирования.\n\n2. На обучающей выборке построй лес из 1000 деревьев.\n\n3. Построй ROC-кривые оценнных моделей на тестовой выборке. \n\n4. Сравни качество всех построенных моделей на тестовой выборке с помощью площади под ROC-кривой.\n\n5. Для наилучшей модели и выбранного на глаз порога для вероятности посчитай таблицу сопряжённости.\n\nЧисло групп (fold) в кросс-валидации бери равным пяти. В качестве целевого показателя — площадь под ROC-кривой. Группу студента в модели (1) можно не учитывать.\n\n*Подсказка от добрых гномов: ну ты помнишь? и рандомизацию ещё фиксировать?*","metadata":{}},{"cell_type":"markdown","source":"## Задачулька 4\n\nЕсли ты супер крут и решил прошлые задачки, а времени ещё вагон, то можешь получить бонусные баллы! \n\nПридумай новые фичи, подбери алгоритм прогнозирования, построй симпатичную картинку!\nСосредоточь свои усилия на чём-то одном: либо прогнозировании либо самой оценки, либо бинарного показателя pass.\n\nИ да, [посади дерево](https://www.youtube.com/watch?v=h0gKrN8rDmI)!","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}